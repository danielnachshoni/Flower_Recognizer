{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hw_1_Flowers_calss.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Deep learning -   HW-1\n",
        "\n",
        "Based on the article :Flowers classification using PyTorch\n",
        "By - Michele Di Fazio\n",
        "\n",
        "https://blog.jovian.ai/flowers-classification-using-pytorch-5c30bc8e559c\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Purpose :\n",
        "Implementation of an algorithm that knows how to make a classification for flower types.\n",
        "Database - Public databases of flowers\n",
        "\n"
      ],
      "metadata": {
        "id": "jbnmwV9zNkHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.utils import make_grid\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets.folder import default_loader\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "fC1GP_ZDO480"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "flowers_idx -Data base\n",
        "first Col=ID secend Col =flowerâ€™s specie"
      ],
      "metadata": {
        "id": "C60D74NCO_zz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# idx = pd.read_csv(\"../input/flower-goggle-tpu-classification/flowers_idx.csv\")\n",
        "# idx"
      ],
      "metadata": {
        "id": "n7qucAcNNNgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Base modle\n",
        "1.coumpute the loss func \n",
        "2. adjust the weight by  gradient descend\n",
        "3. compere between the modles and chosse\n"
      ],
      "metadata": {
        "id": "MjhUHQJvQp2C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Base modle\n",
        "1.coumpute the loss func \n",
        "2. adjust the weight by  gradient descend\n",
        "3. compere between the modles and pick the best "
      ],
      "metadata": {
        "id": "vJS1scCaTxbj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "build custom orgianse dataBase with labels use dataset \n",
        "\n",
        "\n",
        "input- cvs_file ,path, transform   \n",
        "\n",
        "\n",
        "code ->build calss of dataset"
      ],
      "metadata": {
        "id": "xdfyk7HwR7_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyTestdata(Dataset):\n",
        "    def __init__(self, csv_file, root_dir, transform=None):\n",
        "        self.label = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.label)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        if torch.is_tensor(index):\n",
        "            index = index.tolist()\n",
        "        \n",
        "        image = os.path.join(self.root_dir, f\"{self.label.iloc[index, 0]}.jpeg\")\n",
        "        image = default_loader(image)\n",
        "        label = self.label.iloc[index, 1]\n",
        "        \n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            \n",
        "        return (image, label)"
      ],
      "metadata": {
        "id": "BxLvUsSkT6aW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transform Code - Kind of validation for the data Base that the images is in the right standard . "
      ],
      "metadata": {
        "id": "FtYsO7m3Urp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "test_ds = MyTestdata(\n",
        "    csv_file=\"../input/flower-goggle-tpu-classification/flowers_idx.csv\",\n",
        "    root_dir=\"../input/flower-goggle-tpu-classification/flower_tpu/flower_tpu/flowers_google/flowers_google\",\n",
        "    transform=transform_test\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "JGZazDa0UPth",
        "outputId": "a72a7bb0-4386-48a6-c79f-3a355c6684ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-8bd88986537d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcsv_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"../input/flower-goggle-tpu-classification/flowers_idx.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mroot_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"../input/flower-goggle-tpu-classification/flower_tpu/flower_tpu/flowers_google/flowers_google\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n",
            "\u001b[0;32m<ipython-input-6-36ed25354520>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, csv_file, root_dir, transform)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mMyTestdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/flower-goggle-tpu-classification/flowers_idx.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add the other Two data base - \n",
        "\n",
        "\n",
        "1.104 Flowers: Garden of Eden\n"
      ],
      "metadata": {
        "id": "zmY3zbgiVGNq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wZT5fYRFWjUs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.  Flower google tpu classification"
      ],
      "metadata": {
        "id": "8Zqw7RxtVXPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(128, padding=4, padding_mode=\"reflect\"),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor()\n",
        "    #transforms.Normalize([.5, .5, .5], [.5, .5, .5])\n",
        "])\n",
        "    \n",
        "train_ds = torchvision.datasets.ImageFolder(\n",
        "    root=\"../input/104-flowers-garden-of-eden/jpeg-192x192/train\",\n",
        "    transform=transform_train\n",
        ")"
      ],
      "metadata": {
        "id": "B94JdvRzVfST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(128, padding=4, padding_mode=\"reflect\"),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor()\n",
        "    #transforms.Normalize([.5, .5, .5], [.5, .5, .5])\n",
        "])\n",
        "    \n",
        "train_ds = torchvision.datasets.ImageFolder(\n",
        "    root=\"../input/104-flowers-garden-of-eden/jpeg-192x192/train\",\n",
        "    transform=transform_train\n",
        ")"
      ],
      "metadata": {
        "id": "O1UDWWVpVbF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DataLoader= help to arrange the data after the transforming .\n",
        "batch_sise = anount of input . \n",
        "\n",
        "shuffle=true mix the images in the class. "
      ],
      "metadata": {
        "id": "MDCVFdwhWnIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128 \n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=3, pin_memory=True)\n",
        "val_dl = DataLoader(val_ds, batch_size, num_workers=3, pin_memory=True)"
      ],
      "metadata": {
        "id": "NQFx5If_XcY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simulator gives a view based on the data."
      ],
      "metadata": {
        "id": "SUImVZIwXk5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_batch(train_dl):\n",
        "    for images, labels in train_dl:\n",
        "        fig, ax = plt.subplots(figsize=(16,16))\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "        ax.imshow(make_grid(images[:64], nrow=8).permute(1,2,0))\n",
        "        break"
      ],
      "metadata": {
        "id": "5h3LxcbOXqOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "bulid ImageClassificationBase class sub class help to clac the loss func and train the modal  \n",
        "\n",
        "accuracy =numerical value that helps to assimilate how much the model is accurate.\n",
        "\n",
        "training_step = calc the loss function.\n",
        "which in this case will be the **cross-entropy loss**( special type of loss function)\n",
        "\n"
      ],
      "metadata": {
        "id": "4b8CMMAfXnAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def accuracy(out, labels):\n",
        "    _, preds = torch.max(out, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
        "\n",
        "\n",
        "class ImageClassificationBase(nn.Module):\n",
        "    \n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)\n",
        "        loss = F.cross_entropy(out, labels)\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)\n",
        "        loss = F.cross_entropy(out, labels)\n",
        "        acc = accuracy(out, labels)\n",
        "        return {\"val_loss\": loss.detach(), \"val_acc\": acc}\n",
        "    \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x[\"val_loss\"] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()\n",
        "        batch_acc = [x[\"val_acc\"] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_acc).mean()\n",
        "        return {\"val_loss\": epoch_loss.item(), \"val_acc\": epoch_acc.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "            print(\"Epoch: [{}], last_lr: {:.6f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "                epoch, result[\"lrs\"][-1], result[\"train_loss\"], result[\"val_loss\"], result[\"val_acc\"]))"
      ],
      "metadata": {
        "id": "msbwTIh8YRaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "convolution=operation whereby a kernel, The structure of the model\n",
        "\n",
        "scan the image - by slides over the image collact the information from a few images into a \"limited space\". \n",
        "this type of structure help us Define W The model as a unique model,  store more information about the image.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MQR1jhZ7aj8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet18 = models.resnet18()\n",
        "resnet18\n"
      ],
      "metadata": {
        "id": "0obF4ia1YQsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "in this moddle uses resent 34 .\n",
        "\n"
      ],
      "metadata": {
        "id": "77oDTbsNc0tT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definition of three mechanisms that help us control the running of the algorithm:\n",
        "\n",
        "\n",
        "\n",
        "  forward- Running and self-learning\n",
        "\n",
        "freeze- Reboots the parameters, will help to refine the algorithm later.\n",
        "\n",
        "unfreeze- Set the parameters as good parameters."
      ],
      "metadata": {
        "id": "OHk9-Z2nGfVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class flowers_resnet(ImageClassificationBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network = models.resnet34(pretrained=True)\n",
        "        number_features = self.network.fc.in_features\n",
        "        self.network.fc = nn.Linear(number_features, 104)\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        return torch.sigmoid(self.network(xb))\n",
        "    \n",
        "    def freeze(self):\n",
        "        for param in self.network.parameters():\n",
        "            param.require_grad = False\n",
        "        for param in self.network.fc.parameters():\n",
        "            param.require_grad = True\n",
        "            \n",
        "    def unfreeze(self):\n",
        "        for param in self.network.parameters():\n",
        "            param.require_grad = True"
      ],
      "metadata": {
        "id": "EWlRl1L7dRZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use of colab gpu.\n",
        "\n",
        "\n",
        " The explanation is that the program needs a processor with many cores to perform a calculation at the same time if running on the PC (without gpu) could lead to the crash of the computer."
      ],
      "metadata": {
        "id": "nj64ftmgd6vR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def select_device():\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device(\"cuda\")\n",
        "    else:\n",
        "        return torch.device(\"cpu\")\n",
        "\n",
        "def to_device(data, device):\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        for x in self.dl:\n",
        "            yield to_device(x, self.device)\n",
        "            \n",
        "    def __len__(self):\n",
        "        return len(self.dl)"
      ],
      "metadata": {
        "id": "eK95WTaRfMg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "check if GPU is  available"
      ],
      "metadata": {
        "id": "kGdrBHRafS60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = select_device()\n",
        "device"
      ],
      "metadata": {
        "id": "eRE9uqN_fclV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "outputId": "fb80bdf4-5999-4cfe-e4d8-3f3b330d50b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-83f1b7a04628>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'select_device' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = DeviceDataLoader(train_dl, device)\n",
        "val_dl = DeviceDataLoader(val_dl, device)"
      ],
      "metadata": {
        "id": "bdjiS4uQfsSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "last part of the moddle will define method to evaluate the modal in each epoch(loop) complate. \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5Jk3byitf5Q9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, val_dl):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_dl]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group[\"lr\"]\n",
        "    \n",
        "def fit_one_cycle(epochs, max_lr, model, train_dl, val_dl, weight_decay=0, \n",
        "                  grad_clip=None, opt_func=torch.optim.Adam):\n",
        "    torch.cuda.empty_cache()\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
        "    \n",
        "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs,\n",
        "                                               steps_per_epoch=len(train_dl))\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = []\n",
        "        lrs = []\n",
        "        for batch in tqdm(train_dl):\n",
        "            loss = model.training_step(batch)\n",
        "            train_loss.append(loss)\n",
        "            loss.backward()\n",
        "            \n",
        "            if grad_clip:\n",
        "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
        "            \n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            lrs.append(get_lr(optimizer))\n",
        "            sched.step()\n",
        "            \n",
        "        result = evaluate(model, val_dl)\n",
        "        result[\"train_loss\"] = torch.stack(train_loss).mean().item()\n",
        "        result[\"lrs\"] = lrs\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history"
      ],
      "metadata": {
        "id": "IAi1hPm-gfl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = to_device(flowers_resnet(), device)"
      ],
      "metadata": {
        "id": "8j7VsRLXgqLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting  info about the modle \n"
      ],
      "metadata": {
        "id": "Bv1EIpEQgxk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = [evaluate(model, val_dl)]\n",
        "history"
      ],
      "metadata": {
        "id": "-1DH1znRhAjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model.freeze()"
      ],
      "metadata": {
        "id": "2Q6YtR62hEaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.freeze()"
      ],
      "metadata": {
        "id": "-r36lNYJhDkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***One of the most important parts of the model***\n",
        "\n",
        "by editing this part we can improve our module for better result- \n",
        "\n",
        "To answer the question of how to improve the algorithm we based our answer on \n",
        "the following article -Understanding Learning Rates and How It Improves Performance in Deep Learning\n",
        "\n",
        "https://towardsdatascience.com/understanding-learning-rates-and-how-it-improves-performance-in-deep-learning-d0d4059c1c10\n",
        "\n",
        "\n",
        "\n",
        "epochs - one of the heyper parameterthat define the number of times that the algorithm will \"run\" on the entire dataset.\n",
        "**A larger number of epochs can improve the model and produce better results, but on the other hand can extend the model time greatly and is not at all sure that it will improve the model..**\n",
        "\n",
        "-- To answer on \n",
        "\n",
        "\n",
        "\n",
        "max_lr =learining rate=  another hyperparameter that controls how much influencing the weight respect on the loss gradient. \n",
        "\n",
        "lower value slower =low leraning rate meanis There will be a smaller chance of missing a  point in the modelcan help the  be more accurate,\n",
        "If so a low rate can extend our model learning time significantly.\n",
        "\n",
        "\n",
        "grad_clip - Resets the gradient vector, making the model more \"flexible\"\n",
        "\n",
        "\n",
        "weight_decay- How important is W.\n",
        "\n",
        "\n",
        "opt_func - Is the direction of progress to the maximum optimum.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ne8H5ugRhNbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "history += fit_one_cycle(epochs, max_lr, model, train_dl, val_dl,\n",
        "                         grad_clip=grad_clip, weight_decay=weight_decay, \n",
        "                         opt_func=opt_func)"
      ],
      "metadata": {
        "id": "Sfap8epfhnOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.unfreeze()"
      ],
      "metadata": {
        "id": "YyPH4zuphpfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "history += fit_one_cycle(epochs, max_lr, model, train_dl, val_dl,\n",
        "                         grad_clip=grad_clip, weight_decay=weight_decay, \n",
        "                         opt_func=opt_func)"
      ],
      "metadata": {
        "id": "KXXMqtk8hrj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model until reached 86% Expected to take about 10 minutes"
      ],
      "metadata": {
        "id": "AzyrScRZi44-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "present the performance of the model with plots "
      ],
      "metadata": {
        "id": "OvhY0ZPPji0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss(histroy):\n",
        "    val_loss = [x[\"val_loss\"] for x in history]\n",
        "    train_loss = [x.get(\"train_loss\") for x in history]\n",
        "    plt.plot(val_loss, \"-rx\")\n",
        "    plt.plot(train_loss, \"-bx\")\n",
        "    plt.title(\"Loss vs. number of epochs\")\n",
        "    plt.legend([\"Validation loss\", \"Training loss\"])\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "\n",
        "plot_loss(history)"
      ],
      "metadata": {
        "id": "MvZdqsXNhvDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-qKb2KM_jx6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_accuracy(history):\n",
        "    accuracy = [x[\"val_acc\"] for x in history]\n",
        "    plt.plot(accuracy, \"-x\")\n",
        "    plt.title(\"Accuracy vs. number of epochs\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    \n",
        "plot_accuracy(history)"
      ],
      "metadata": {
        "id": "9bZsqo6Hh0WZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "move the images of the test dataset to the GPU, and to pass them through our model"
      ],
      "metadata": {
        "id": "ofj8skBOlW-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(images, model):\n",
        "    xb = to_device(images.unsqueeze(0), device)\n",
        "    out = model(xb)\n",
        "    _, preds = torch.max(out, dim=1)\n",
        "    return train_ds.classes[preds[0].item()]"
      ],
      "metadata": {
        "id": "wpxcfQZvh6Mw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "image 1 "
      ],
      "metadata": {
        "id": "cqQjntTDleKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = test_ds[100]\n",
        "plt.imshow(images.permute(1,2,0))\n",
        "print(\"Label: \", labels, \"Prediction:\", prediction(images, model))"
      ],
      "metadata": {
        "id": "pjz3XpREh7MS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "image 2"
      ],
      "metadata": {
        "id": "x1ddtEDVliVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = test_ds[200]\n",
        "plt.imshow(images.permute(1,2,0))\n",
        "print(\"Label: \", labels, \"Prediction:\", prediction(images, model))"
      ],
      "metadata": {
        "id": "OUQF1hLTh-9P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
